{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ajaysohmshetty/anaconda2/bin/python\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import model_utils, data_utils\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "import sys\n",
    "print sys.executable\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "from pipeline import *\n",
    "from data_utils import *\n",
    "from utils import *\n",
    "import vis\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cifar batch training batch 1 of 1\n",
      "loading cifar batch testing batch 1 of 1\n"
     ]
    }
   ],
   "source": [
    "X_train_gate, y_train_gate, fine_or_coarse_train_gate = data_utils.load_data_pyramid(return_subset=\"gate_only\")\n",
    "#load_data_pyramid(return_subset=\"test_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 15  4 ...,  8  7  1]\n",
      "[19 29  0 ...,  3  7  0]\n",
      "40.0\n"
     ]
    }
   ],
   "source": [
    "c, f = form_y_for_cnn_rnn(y_train_gate, fine_or_coarse_train_gate, 20, 100)\n",
    "print c-100\n",
    "f[f==120] = 0\n",
    "print f\n",
    "counts = np.zeros(100)\n",
    "counts[f] = 1\n",
    "print np.sum(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def form_y_for_cnn_rnn(y, fine_or_coarse_gate, coarse_dim, fine_dim):\n",
    "    coarse_indexes, fine_indexes = y[:, 1] + fine_dim, y[:, 0]\n",
    "    total_dim = coarse_dim + fine_dim + 1\n",
    "\n",
    "    locations_of_end_token = fine_or_coarse_gate * -2 + 1  # 1 for not end token, -1 for end token\n",
    "    fine_indexes = fine_indexes * locations_of_end_token  # any end token now has negative index\n",
    "    fine_indexes[fine_indexes < 0] = total_dim - 1  # swap negative for end token\n",
    "\n",
    "    return coarse_indexes, fine_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load dataset cifar100_joint_fine_only ...\n",
      "loading cifar batch training batch 1 of 1\n",
      "loading cifar batch testing batch 1 of 1\n"
     ]
    }
   ],
   "source": [
    "from data_utils import load_data\n",
    "\n",
    "X, Y, X_test, Y_test = load_data(dataset=\"cifar100_joint_fine_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = 3000\n",
    "mask = np.asarray(range(1,101))\n",
    "mask = np.tile(mask, num_examples)\n",
    "mask = np.reshape(mask, (num_examples, 100))\n",
    "masked = mask * Y_test\n",
    "tallies = np.sum(masked, axis=0)\n",
    "tallies[tallies>0] = 1\n",
    "np.sum(tallies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "stuff = pickle.load(open(\"../data/feature_sets/cifar100_joint_prefeaturized\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_featured = stuff[0]\n",
    "X_featured = np.asarray(X_featured)\n",
    "X_featured = X_featured[0:10]\n",
    "X_featured.shape\n",
    "# need to make from 10, 512 to 10, 2, 512 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 13.65108585  13.45428276   0.         ...,   0.           0.           0.        ]\n",
      " [ 13.65108585  13.45428276   0.         ...,   0.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "test = np.tile(X_featured, (1, 2))\n",
    "test = np.reshape(test, (10, 2, 512))\n",
    "\n",
    "print test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shape after lstm...\n",
      "(?, 121)\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "n_output_units = 2\n",
    "prefeature_embedding_size = 512\n",
    "single_output_token_size = (100 + 20 + 1)\n",
    "\n",
    "net = input_data(shape=[None, prefeature_embedding_size])\n",
    "\n",
    "# Basically, this repeats the input several times to be fed into the LSTM\n",
    "net = tf.tile(net, [1, n_output_units])\n",
    "net = tf.reshape(net, [-1, n_output_units, prefeature_embedding_size])\n",
    "\n",
    "#\n",
    "net = tflearn.lstm(net, single_output_token_size, return_seq=True) # This returns [# of samples, # of timesteps, output dim]\n",
    "print(\"Printing shape after lstm...\")\n",
    "print(net[0].get_shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_gate1 = stuff[1]\n",
    "print y_train_gate1.shape\n",
    "test = np.asarray(range(30))\n",
    "# [None, n_output_units, prefeature_size]\n",
    "test = test.reshape((3, 2, 5))\n",
    "print test[0]\n",
    "test = test.reshape(3, 10)\n",
    "print test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def form_y_for_cnn_rnn(y, fine_or_coarse_gate, coarse_dim=20, fine_dim=100):\n",
    "    coarse_indexes, fine_indexes = y[:,1] + fine_dim, y[:,0]\n",
    "    total_dim = coarse_dim + fine_dim + 1\n",
    "    \n",
    "    # next, zero out the fine_one_hots according to gate \n",
    "    locations_of_end_token = fine_or_coarse_gate*-2 +1 # 1 for not end token, -1 for end token \n",
    "    fine_indexes = fine_indexes * locations_of_end_token # any end token now has negative index    \n",
    "    fine_indexes[fine_indexes<0] = total_dim-1 # swap negative for end token \n",
    "    \n",
    "    coarse_one_hots = to_categorical(coarse_indexes, total_dim)\n",
    "    fine_one_hots = to_categorical(fine_indexes, total_dim)\n",
    "    \n",
    "    y_joint = np.concatenate((coarse_one_hots, fine_one_hots), axis=1)\n",
    "    \n",
    "    return y_joint\n",
    "\n",
    "y_train = form_y_for_cnn_rnn(y_train_gate, fine_or_coarse_train_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coarse_dim = 20\n",
    "fine_dim = 100\n",
    "X_train_joint, y_train_joint = data_utils.load_data_pyramid(return_subset='joint_only')\n",
    "X_train_joint, y_train_joint = shuffle(X_train_joint, y_train_joint)\n",
    "y_train_fine, y_train_coarse = y_train_joint[:, 0], y_train_joint[:, 1]\n",
    "y_train_fine, y_train_coarse = to_categorical(y_train_fine, fine_dim), to_categorical(y_train_coarse, coarse_dim)\n",
    "\n",
    "y_train_joint = np.concatenate((y_train_coarse, y_train_fine), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y_train_joint.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = unpickle(\"../data/cifar-100-python/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in batch.iteritems():\n",
    "    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = batch['data']\n",
    "fine_labels = batch['fine_labels']\n",
    "coarse_labels = batch['coarse_labels']\n",
    "batch_label = batch['batch_label']\n",
    "filenames = batch['filenames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches_meta = unpickle(\"../data/cifar-100-python/meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in batches_meta.iteritems():\n",
    "    print k, v[:10]\n",
    "    print \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches_meta = unpickle(\"../data/cifar-10-batches-py/batches.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in batches_meta.iteritems():\n",
    "    print k, v\n",
    "    print \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superclass\tClasses\n",
    "aquatic mammals\tbeaver, dolphin, otter, seal, whale\n",
    "fish\taquarium fish, flatfish, ray, shark, trout\n",
    "flowers\torchids, poppies, roses, sunflowers, tulips\n",
    "food containers\tbottles, bowls, cans, cups, plates\n",
    "fruit and vegetables\tapples, mushrooms, oranges, pears, sweet peppers\n",
    "household electrical devices\tclock, computer keyboard, lamp, telephone, television\n",
    "household furniture\tbed, chair, couch, table, wardrobe\n",
    "insects\tbee, beetle, butterfly, caterpillar, cockroach\n",
    "large carnivores\tbear, leopard, lion, tiger, wolf\n",
    "large man-made outdoor things\tbridge, castle, house, road, skyscraper\n",
    "large natural outdoor scenes\tcloud, forest, mountain, plain, sea\n",
    "large omnivores and herbivores\tcamel, cattle, chimpanzee, elephant, kangaroo\n",
    "medium-sized mammals\tfox, porcupine, possum, raccoon, skunk\n",
    "non-insect invertebrates\tcrab, lobster, snail, spider, worm\n",
    "people\tbaby, boy, girl, man, woman\n",
    "reptiles\tcrocodile, dinosaur, lizard, snake, turtle\n",
    "small mammals\thamster, mouse, rabbit, shrew, squirrel\n",
    "trees\tmaple, oak, palm, pine, willow\n",
    "vehicles 1\tbicycle, bus, motorcycle, pickup truck, train\n",
    "vehicles 2\tlawn-mower, rocket, streetcar, tank, tractor\n",
    "\n",
    "Yes, I know mushrooms aren't really fruit or vegetables and bears aren't really carnivores. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
